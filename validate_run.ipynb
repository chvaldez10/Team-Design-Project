{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Processing for BT Lab\n",
    "Functions to check if run is good\n",
    "<br>\n",
    "<br>\n",
    "![UofC logo](./pictures/uofc_logo-black.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from timeit import default_timer as timer\n",
    "import cv2\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "# plot\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faster r-cnn\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sk libraries\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure to update path\n",
    "user_drive = input(\"Enter user drive: \").upper()\n",
    "video_path = f\"{user_drive}:/Christian/DI_centre_structured\"\n",
    "input(f\"Is this the right directory - {video_path}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_CHARACTERISTICS = {\n",
    "    \"With Blankets\" : \"WB\",\n",
    "    \"B\" : \"WB\",\n",
    "    \"Without Blankets\" : \"WOB\",\n",
    "    \"WOB\": \"WOB\",\n",
    "    \"3 Meters\" : \"3m\",\n",
    "    \"2 Meters\" : \"2m\",\n",
    "    \"Hold Breath\" : \"HB\",\n",
    "    \"Hold Breathe\" : \"HB\",\n",
    "    \"H\" : \"HB\",\n",
    "    \"Relaxed\" : \"rel\",\n",
    "    \"R\": \"rel\",\n",
    "}\n",
    "\n",
    "# for testing\n",
    "FRAME_LIMIT = 100\n",
    "\n",
    "# limit for storage\n",
    "MINIMUM_FREE_SPACE_GB = 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local dirs\n",
    "repo_dir = os.getcwd()\n",
    "json_dir = repo_dir + \"/records/JSON\"\n",
    "log_dir = repo_dir + \"/records/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_frame_paths(local_path: str, level: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Constructs and returns paths related to video frames.\n",
    "\n",
    "    Parameters:\n",
    "    local_path (str): The local file path of the video.\n",
    "    level (str): The detail level for the frames.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list containing the folder path for frames and the video folder path.\n",
    "    \"\"\"\n",
    "    video_folder, video_filename_with_ext = os.path.split(local_path)\n",
    "    video_filename = os.path.splitext(video_filename_with_ext)[0]\n",
    "    folder_path = os.path.join(video_folder, f\"frames_{video_filename}_{level}\")\n",
    "    return [folder_path, video_folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_frames(old_fps: int, new_fps: int, start: int) -> List[int]:\n",
    "    \"\"\"\n",
    "    Resamples the number of frames from an old frame rate to a new frame rate. \n",
    "    This function can handle both upsampling and downsampling.\n",
    "\n",
    "    Parameters:\n",
    "    old_fps (int): The original frames per second.\n",
    "    new_fps (int): The new frames per second to resample to.\n",
    "    start (int): The starting frame index.\n",
    "\n",
    "    Returns:\n",
    "    List[int]: A list of frame indices after resampling.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If old_fps or new_fps are non-positive integers.\n",
    "    \"\"\"\n",
    "    if old_fps <= 0 or new_fps <= 0:\n",
    "        raise ValueError(\"old_fps and new_fps must be positive integers.\")\n",
    "\n",
    "    original_frame_indices = np.arange(start, old_fps, dtype=int)\n",
    "    interpolated_frame_positions = np.linspace(start, old_fps - 1, new_fps)\n",
    "    nearest_frame_indices = np.round(interpolated_frame_positions).astype(int)\n",
    "    resampled_frame_indices = np.take(original_frame_indices, nearest_frame_indices, mode='wrap')\n",
    "\n",
    "    return resampled_frame_indices.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_patient_video_id(patient_data: dict, video_count: int) -> str:\n",
    "    \"\"\"\n",
    "    Creates a unique ID for a patient video scenario.\n",
    "\n",
    "    Parameters:\n",
    "    patient_data (dict): Dictionary containing patient information.\n",
    "    video_count (int): The count of videos for the patient.\n",
    "\n",
    "    Returns:\n",
    "    str: A unique ID string for the video.\n",
    "    \"\"\"\n",
    "    alias = patient_data.get(\"alias\", \"Unknown\")\n",
    "    blanket = VIDEO_CHARACTERISTICS.get(patient_data.get(\"blanket\", \"\"), \"?\")\n",
    "    distance = VIDEO_CHARACTERISTICS.get(patient_data.get(\"distance\", \"\").title(), \"?\")\n",
    "    breathing = VIDEO_CHARACTERISTICS.get(patient_data.get(\"breathing\", \"\"), \"?\")\n",
    "\n",
    "    return f\"{alias}_{video_count}-{distance}-{blanket}-{breathing}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_exists(folder_path: str) -> bool:\n",
    "    \"\"\"Checks if the specified folder exists.\"\"\"\n",
    "    return os.path.exists(folder_path)\n",
    "\n",
    "def extract_video_metadata(video_path: str) -> Tuple[int, int]:\n",
    "    \"\"\"Extracts metadata from the video file.\"\"\"\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    if not video.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video file {video_path}\")\n",
    "\n",
    "    try:\n",
    "        vid_fps = int(video.get(cv2.CAP_PROP_FPS))\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    finally:\n",
    "        video.release()\n",
    "\n",
    "    return vid_fps, total_frames\n",
    "\n",
    "def calculate_expected_frame_count(vid_fps: int, total_frames: int, new_fps: int) -> int:\n",
    "    \"\"\"Calculates the expected number of frames.\"\"\"\n",
    "    vid_duration = total_frames // vid_fps\n",
    "    return new_fps * vid_duration\n",
    "\n",
    "def count_frames_in_folder(folder_path: str) -> int:\n",
    "    \"\"\"Counts the number of frames (files) in the given folder.\"\"\"\n",
    "    return len(os.listdir(folder_path))\n",
    "\n",
    "def run_folder_check(video_path: str, save_folder: str, new_fps: int) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Checks if the specified folder has the correct number of frames extracted from a video.\n",
    "    Returns the folder path if the frame count does not match.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        vid_fps, total_frames = extract_video_metadata(video_path)\n",
    "        expected_frame_count = calculate_expected_frame_count(vid_fps, total_frames, new_fps)\n",
    "        actual_frame_count = count_frames_in_folder(save_folder)\n",
    "\n",
    "        if actual_frame_count != expected_frame_count:\n",
    "            print(f\"{save_folder} - Incorrect frame count. Found {actual_frame_count}, expected {expected_frame_count}.\")\n",
    "            return save_folder\n",
    "    except RuntimeError as e:\n",
    "        print(str(e))\n",
    "        return None\n",
    "\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# driver code for checking empty folders\n",
    "def validate_run(all_patients:dict, level: str, new_fps:int) -> list:\n",
    "    visited_folders = {}    \n",
    "    rerun_folders = []\n",
    "    frames_folders = []\n",
    "\n",
    "    for json_index, patient_info in all_patients.items():\n",
    "        try:\n",
    "            video_path = patient_info[\"local path\"]\n",
    "            old_fps = int(patient_info[\"old fps\"])\n",
    "\n",
    "            frames_folder, video_folder = get_video_frame_paths(video_path, level)\n",
    "            visited_folders[video_folder] = visited_folders.get(video_folder, 0) + 1\n",
    "            frames_folders.append(frames_folder)\n",
    "\n",
    "            frames_to_pick = resample_frames(old_fps, new_fps, 1)\n",
    "\n",
    "            if len(frames_to_pick) != new_fps:\n",
    "                raise ValueError(\"Number of frames to pick is not equal to new fps\")\n",
    "\n",
    "            # checks if a folder has the correct number of frames\n",
    "            rerun_folder = run_folder_check(video_path, frames_folder, new_fps)\n",
    "            \n",
    "            if rerun_folder != None:\n",
    "                print(\"Need to rerun folder: \", rerun_folder)\n",
    "                rerun_folders.append(rerun_folder)\n",
    "\n",
    "        except Exception as e:\n",
    "            traceback.print_exc()\n",
    "            print(f'''{type(e)}: {e} for video {patient_info[\"filename\"]}''')\n",
    "\n",
    "    return [rerun_folders, frames_folders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to json\n",
    "\n",
    "def export_to_json(filename: str, all_patient_info: dict) -> None:\n",
    "    patient_json = json.dumps(all_patient_info, indent=2)\n",
    "\n",
    "    with open(filename, \"w\") as json_data:\n",
    "        json_data.write(patient_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(json_dir: str, filename: str) -> dict:\n",
    "    # Remove leading slash if present in filename\n",
    "    if filename.startswith(\"/\"):\n",
    "        filename = filename[1:]\n",
    "\n",
    "    full_path = os.path.join(json_dir, filename)\n",
    "\n",
    "    try:\n",
    "        with open(full_path, \"r\") as json_data:\n",
    "            return json.load(json_data)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {full_path} does not exist.\")\n",
    "        return {}\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Error: The file {full_path} is not a valid JSON.\")\n",
    "        return {} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" local vars\"\"\"\n",
    "\n",
    "rgb_fps = {\n",
    "    \"lower_bound\": 10,\n",
    "    \"upper_bound\": 20\n",
    "}\n",
    "\n",
    "thermal_fps = {\n",
    "    \"lower_bound\": 5,\n",
    "    \"upper_bound\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load JSON files \"\"\"\n",
    "\n",
    "metadata_rgb = load_json(json_dir, \"/rgb_complete.json\")\n",
    "metadata_thermal = load_json(json_dir, \"/thermal_complete.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjusting FPS to 10\n",
      "==================================================\n",
      "C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\With Blankets\\Relaxed\\frames_Arun2_lower_bound - Incorrect frame count. Found 17, expected 20.\n",
      "Need to rerun folder:  C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\With Blankets\\Relaxed\\frames_Arun2_lower_bound\n",
      "C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\Without Blankets\\Hold Breath\\frames_short_lower_bound - Incorrect frame count. Found 17, expected 290.\n",
      "Need to rerun folder:  C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\Without Blankets\\Hold Breath\\frames_short_lower_bound\n",
      "C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\Without Blankets\\Relaxed\\frames_relax 2meter short_lower_bound - Incorrect frame count. Found 17, expected 640.\n",
      "Need to rerun folder:  C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\Without Blankets\\Relaxed\\frames_relax 2meter short_lower_bound\n",
      "\n",
      "Adjusting FPS to 20\n",
      "==================================================\n",
      "C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\With Blankets\\Hold Breath\\frames_Arun2_upper_bound - Incorrect frame count. Found 34, expected 700.\n",
      "Need to rerun folder:  C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\With Blankets\\Hold Breath\\frames_Arun2_upper_bound\n",
      "C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\With Blankets\\Relaxed\\frames_Arun2_upper_bound - Incorrect frame count. Found 34, expected 40.\n",
      "Need to rerun folder:  C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\With Blankets\\Relaxed\\frames_Arun2_upper_bound\n",
      "C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\Without Blankets\\Hold Breath\\frames_short_upper_bound - Incorrect frame count. Found 34, expected 580.\n",
      "Need to rerun folder:  C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\Without Blankets\\Hold Breath\\frames_short_upper_bound\n",
      "C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\Without Blankets\\Relaxed\\frames_relax 2meter short_upper_bound - Incorrect frame count. Found 34, expected 1280.\n",
      "Need to rerun folder:  C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun\\2 Meters\\Without Blankets\\Relaxed\\frames_relax 2meter short_upper_bound\n"
     ]
    }
   ],
   "source": [
    "\"\"\" check videos (rgb) \"\"\"\n",
    "all_rgb_folders = []\n",
    "all_rgb_rerun_folders = []\n",
    "\n",
    "for level, new_fps in rgb_fps.items():\n",
    "    print(f\"\\nAdjusting FPS to {new_fps}\\n\" + \"=\"*50)\n",
    "    rerun_folders, visited_folders = validate_run(metadata_rgb, level, new_fps)\n",
    "    all_rgb_rerun_folders.append(rerun_folders)\n",
    "    all_rgb_folders.append(visited_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' check videos (thermal) '"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" check videos (thermal) \"\"\"\n",
    "# all_thermal_folders = []\n",
    "# all_thermal_rerun_folders = []\n",
    "\n",
    "# for level, new_fps in thermal_fps.items():\n",
    "#     print(f\"\\nAdjusting FPS to {new_fps}\\n\" + \"=\"*50)\n",
    "#     rerun_folders, visited_folders = check_if_empty_folders(metadata_thermal, level, new_fps, user_drive)\n",
    "#     all_thermal_folders.append(visited_folders)\n",
    "#     all_thermal_rerun_folders.append(rerun_folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img, model, threshold=0.5):\n",
    "    # Convert the image to RGB and then to a tensor\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    img_tensor = transform(img_rgb)\n",
    "\n",
    "    # Put the model in evaluation mode and apply to the image\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model([img_tensor])\n",
    "\n",
    "    # Collect bounding boxes\n",
    "    bboxes = []\n",
    "    for element in range(len(prediction[0]['boxes'])):\n",
    "        if prediction[0]['scores'][element] > threshold:\n",
    "            box = prediction[0]['boxes'][element].cpu().numpy()\n",
    "            label = prediction[0]['labels'][element].cpu().numpy()\n",
    "            \n",
    "            if label == 1:  # COCO Dataset label for 'person'\n",
    "                bboxes.append(box)\n",
    "\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\chris\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load a pre-trained Faster R-CNN model\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun/2 Meters/With Blankets/Hold Breath/frames_Arun2_lower_bound',\n",
       " 'C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun/2 Meters/With Blankets/Relaxed/frames_Arun2_lower_bound',\n",
       " 'C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun/2 Meters/Without Blankets/Hold Breath/frames_short_lower_bound',\n",
       " 'C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun/2 Meters/Without Blankets/Relaxed/frames_relax 2meter short_lower_bound']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rgb_lower_bound, all_rgb_upper_bound = all_rgb_folders\n",
    "all_rgb_lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Christian/DI_centre_structured/DI_CAMERA_P3225/Final/Arun/2 Meters/With Blankets/Hold Breath/frames_Arun2_lower_bound/15_1-2m-WB-HB_0.png\n",
      "Detected bounding boxes: [array([  82.82521,  316.22778,  785.2172 , 1029.9728 ], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "for rgb_folder in all_rgb_lower_bound:\n",
    "    first_image = rgb_folder + \"/\" + os.listdir(rgb_folder)[0]\n",
    "    print(first_image)\n",
    "\n",
    "    img = cv2.imread(first_image)\n",
    "\n",
    "    if img is None:\n",
    "        print(\"Error: Could not read the image.\")\n",
    "    else:\n",
    "        bounding_boxes = detect_objects(img, model)\n",
    "        print(\"Detected bounding boxes:\", bounding_boxes)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets labels based on breathing\n",
    "\n",
    "def get_label_breathing(visited_folders: list[str]) -> [list, list]:\n",
    "    all_frames_path = []\n",
    "    all_labels = []\n",
    "\n",
    "    hold_breath_pattern = r\"/Hold Breath/|/Hold Breathe/|/H/\"\n",
    "    relaxed_pattern = r\"/Relaxed/|/R/\"\n",
    "\n",
    "    for visited_folder in visited_folders:\n",
    "        if re.search(relaxed_pattern, visited_folder):\n",
    "            all_labels.append(0) # 0 for relaxed pattern\n",
    "        elif re.search(hold_breath_pattern, visited_folder):\n",
    "            all_labels.append(1) # 1 for hold breath pattern\n",
    "        else:\n",
    "            print(f\"Warning: No matching breathing pattern for {visited_folder}\")\n",
    "            continue\n",
    "\n",
    "        all_frames_path.append(visited_folder)\n",
    "\n",
    "    return [all_frames_path, all_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get labels for rgb\n",
    "\n",
    "# all_rgb_frames_path = []\n",
    "# all_rgb_labels = []\n",
    "# save_data = {}\n",
    "\n",
    "# for fps_bound in all_rgb_folders:\n",
    "#     tmp_path_list, tmp_labels_list = get_label_breathing(fps_bound)\n",
    "#     all_rgb_frames_path += tmp_path_list\n",
    "#     all_rgb_labels += tmp_labels_list\n",
    "\n",
    "# save_data[\"frames_path\"] = all_rgb_frames_path\n",
    "# save_data[\"labels_path\"] = all_rgb_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save test train split in json data (rgb)\n",
    "# save_rgb_filename = json_dir + \"/training_test_split/rgb_labels.json\"\n",
    "# export_to_json(save_rgb_filename, save_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "\n",
    "def split_data(all_videos: list[str], all_labels: list[int]):\n",
    "    train_videos, test_videos, train_labels, test_labels = train_test_split(\n",
    "        all_videos, all_labels, test_size=0.2, random_state=42)\n",
    "    return train_videos, test_videos, train_labels, test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data (rgb)\n",
    "# train_rgb_frames, test_rgb_frames, train_rgb_labels, test_rgb_labels = train_test_split(\n",
    "#     all_rgb_frames_path, all_rgb_labels, test_size=0.2, random_state=42\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7228a7137a92e95012bf2be7e7bd4e027e828c700167ca5a0671652a2d91aff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
